from keras.models import load_model
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten,Dropout
from keras.optimizers import Adam

# Load oxflower17 dataset
import tflearn.datasets.oxflower17 as oxflower17
from sklearn.model_selection import train_test_split
x, y = oxflower17.load_data(one_hot=True)

#Split train and test data
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle = True)

#Data augumentation with Keras tools
from keras.preprocessing.image import ImageDataGenerator
img_gen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)


# Build AlexNet model
def AlexNet(width, height, depth, classes):
    model = Sequential()

    # First Convolution and Pooling layer
    model.add(
        Conv2D(96, (11, 11), strides=(4, 4), input_shape=(width, height, depth), padding='valid', activation='relu'))
    model.add(MaxPooling2D(pool_size=(5, 5), strides=(2, 2)))

    # Second Convolution and Pooling layer
    model.add(Conv2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))

    # Three Convolution layer and Pooling Layer
    model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'))
    model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'))
    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(5, 5), strides=(2, 2)))

    # Fully connection layer
    model.add(Flatten())
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1000, activation='relu'))
    model.add(Dropout(0.5))

    # Classfication layer
    model.add(Dense(classes, activation='softmax'))

    return model

# AlexNet_model = AlexNet(224,224,3,17)
# AlexNet_model.summary()
# AlexNet_model.compile(optimizer=Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss ='categorical_crossentropy', metrics=['accuracy'])

AlexNet_model = load_model('model/Alexnet.h5')
AlexNet_model.summary()

#Start training using data augumentation generator
History = AlexNet_model.fit_generator(img_gen.flow(X_train*255, y_train, batch_size = 16),
                             steps_per_epoch = len(X_train)/16, validation_data = (X_test,y_test), epochs = 20)

# Save the model
AlexNet_model.save('model/Alexnet.h5')

# evaluate the model
scores = AlexNet_model.evaluate(X_test, y_test, verbose=0)
print("%s: %.2f%%" % (AlexNet_model.metrics_names[1], scores[1]*100))

#Plot Loss and Accuracy

# import matplotlib.pyplot as plt
# plt.figure(figsize = (15,5))
# plt.subplot(1,2,1)
# plt.plot(History.history['acc'])
# plt.plot(History.history['val_acc'])
# plt.title('model accuracy')
# plt.ylabel('accuracy')
# plt.xlabel('epoch')
# plt.legend(['train', 'test'], loc='upper left')
#
# plt.subplot(1,2,2)
# plt.plot(History.history['loss'])
# plt.plot(History.history['val_loss'])
# plt.title('model loss')
# plt.ylabel('loss')
# plt.xlabel('epoch')
# plt.legend(['train', 'test'], loc='upper left')
# plt.show()