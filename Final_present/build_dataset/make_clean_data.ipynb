{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"dark\">Make Clean data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global paramter\n",
    "DATA_train_dir = \"../data/train\"\n",
    "DATA_test_dir = \"../data/test\"\n",
    "DATA_val_dir = \"../data/validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='dark'>Step 1 : Clean garbage data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of data_0 for training : 447\n",
      "The length of data_1 for training : 3044\n",
      "The length of data_0 for test : 56\n",
      "The length of data_1 for test : 380\n",
      "The length of data_0 for val : 56\n",
      "The length of data_1 for val : 380\n"
     ]
    }
   ],
   "source": [
    "# train data\n",
    "train_data_0 = glob.glob(os.path.sep.join([DATA_train_dir, \"data_0/*\"]))\n",
    "train_data_1 = glob.glob(os.path.sep.join([DATA_train_dir, \"data_1/*\"]))\n",
    "# test data\n",
    "test_data_0 = glob.glob(os.path.sep.join([DATA_test_dir, \"data_0/*\"]))\n",
    "test_data_1 = glob.glob(os.path.sep.join([DATA_test_dir, \"data_1/*\"]))\n",
    "# validation data\n",
    "val_data_0 = glob.glob(os.path.sep.join([DATA_val_dir, \"data_0/*\"]))\n",
    "val_data_1 = glob.glob(os.path.sep.join([DATA_val_dir, \"data_1/*\"]))\n",
    "\n",
    "print(\"The length of data_0 for training : %d\" % len(train_data_0))\n",
    "print(\"The length of data_1 for training : %d\" % len(train_data_1))\n",
    "print(\"The length of data_0 for test : %d\" % len(test_data_0))\n",
    "print(\"The length of data_1 for test : %d\" % len(test_data_1))\n",
    "print(\"The length of data_0 for val : %d\" % len(val_data_0))\n",
    "print(\"The length of data_1 for val : %d\" % len(val_data_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole train data length : 3491\n",
      "whole test data length : 436\n",
      "whole val data length : 436\n"
     ]
    }
   ],
   "source": [
    "whole_train_data = train_data_0+train_data_1\n",
    "whole_test_data = test_data_0+test_data_1\n",
    "whole_val_data = val_data_0+val_data_1\n",
    "\n",
    "print(\"whole train data length : %d\" % len(whole_train_data))\n",
    "print(\"whole test data length : %d\" % len(whole_test_data))\n",
    "print(\"whole val data length : %d\" % len(whole_val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='dark'>Step 2 : See the data distribution</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_row_dataframe(whole_data):\n",
    "    width=[]\n",
    "    height = []\n",
    "    file_name = []\n",
    "    label = []\n",
    "\n",
    "    for id_num,file in enumerate(whole_data):\n",
    "        # Add the label\n",
    "        label_val = lambda m,n: 0 if m<n else 1\n",
    "        label.append(label_val(id_num,len(train_data_0)))\n",
    "\n",
    "        # Read the image, Add the width and height\n",
    "        img = cv2.imread(file)\n",
    "        file_name.append(file)\n",
    "        width.append(img.shape[0]); height.append(img.shape[1])\n",
    "\n",
    "    data = pd.DataFrame({\"width\":width,\"height\":height,\"file\":file_name,\"label\":label})\n",
    "    return data\n",
    "\n",
    "train_df = make_row_dataframe(whole_train_data)\n",
    "test_df = make_row_dataframe(whole_test_data)\n",
    "val_df = make_row_dataframe(whole_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "width  height\n",
       "828    1170         1\n",
       "1288   1936        16\n",
       "1869   2800        69\n",
       "2000   2992         3\n",
       "2304   3456         3\n",
       "2592   2592      3399\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_width_height = train_df.groupby([\"width\",\"height\"])\n",
    "print(\"training data\")\n",
    "train_width_height.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "width  height\n",
       "1288   1936        4\n",
       "1869   2800       23\n",
       "2304   3456        2\n",
       "2592   2592      407\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_width_height = test_df.groupby([\"width\",\"height\"])\n",
    "print(\"testing data\")\n",
    "test_width_height.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "width  height\n",
       "1288   1936        7\n",
       "1632   2464        1\n",
       "1824   2736        1\n",
       "1869   2800       26\n",
       "2304   3456        6\n",
       "2592   2592      395\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_width_height = val_df.groupby([\"width\",\"height\"])\n",
    "print(\"testing data\")\n",
    "val_width_height.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the clean data for  training :  (3399, 2)\n",
      "The label destribution of the data for  training : \n",
      " label\n",
      "0     435\n",
      "1    2964\n",
      "dtype: int64 \n",
      "\n",
      "The shape of the clean data for  testing :  (407, 2)\n",
      "The label destribution of the data for  testing : \n",
      " label\n",
      "0    407\n",
      "dtype: int64 \n",
      "\n",
      "The shape of the clean data for  validation :  (395, 2)\n",
      "The label destribution of the data for  validation : \n",
      " label\n",
      "0    395\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_clean_dataframe(train_df,data_type):\n",
    "    # Only image which width is 2592px;\n",
    "    mask = train_df.width==2592\n",
    "    clean_data = train_df[mask].drop(columns=[\"width\",\"height\"])\n",
    "    print(\"The shape of the clean data for \",data_type,\": \",clean_data.shape)\n",
    "    print(\"The label destribution of the data for \",data_type,\": \\n\",clean_data.groupby(\"label\").size(),'\\n')\n",
    "    return clean_data\n",
    "    \n",
    "train_clean_df = make_clean_dataframe(train_df, \"training\")\n",
    "test_clean_df = make_clean_dataframe(test_df, \"testing\")\n",
    "val_clean_df = make_clean_dataframe(val_df, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='dark'>Step 3 : Balance the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label destribution of the data for  train : \n",
      " label\n",
      "0     435\n",
      "1    2164\n",
      "dtype: int64 \n",
      "\n",
      "The label destribution of the data for  test : \n",
      " label\n",
      "0    407\n",
      "1    400\n",
      "dtype: int64 \n",
      "\n",
      "The label destribution of the data for  val : \n",
      " label\n",
      "0    395\n",
      "1    400\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use train data to split\n",
    "train_clean_df = train_clean_df.reset_index(drop=True)\n",
    "# For test\n",
    "test_clean_df = test_clean_df.append(train_clean_df[-400:]).reset_index(drop=True)\n",
    "train_clean_df = train_clean_df[:-400]\n",
    "# For validation\n",
    "val_clean_df = val_clean_df.append(train_clean_df[-400:]).reset_index(drop=True)\n",
    "train_clean_df = train_clean_df[:-400]\n",
    "\n",
    "print(\"The label destribution of the data for \",\"train\",\": \\n\",train_clean_df.groupby(\"label\").size(),'\\n')\n",
    "print(\"The label destribution of the data for \",\"test\",\": \\n\",test_clean_df.groupby(\"label\").size(),'\\n')\n",
    "print(\"The label destribution of the data for \",\"val\",\": \\n\",val_clean_df.groupby(\"label\").size(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='dark'>Step 4 : Saved as CSV</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_df.to_csv(\"../data/train_clean_df.csv\", index=None)\n",
    "test_clean_df.to_csv(\"../data/test_clean_df.csv\", index=None)\n",
    "val_clean_df.to_csv(\"../data/val_clean_df.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label destribution of the data for  train : \n",
      " label\n",
      "0     435\n",
      "1    2164\n",
      "dtype: int64 \n",
      "\n",
      "The label destribution of the data for  test : \n",
      " label\n",
      "0    407\n",
      "1    400\n",
      "dtype: int64 \n",
      "\n",
      "The label destribution of the data for  val : \n",
      " label\n",
      "0    395\n",
      "1    400\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "\n",
    "train_clean_df=pd.read_csv(\"../data/train_clean_df.csv\")\n",
    "test_clean_df=pd.read_csv(\"../data/test_clean_df.csv\")\n",
    "val_clean_df=pd.read_csv(\"../data/val_clean_df.csv\")\n",
    "\n",
    "print(\"The label destribution of the data for \",\"train\",\": \\n\",train_clean_df.groupby(\"label\").size(),'\\n')\n",
    "print(\"The label destribution of the data for \",\"test\",\": \\n\",test_clean_df.groupby(\"label\").size(),'\\n')\n",
    "print(\"The label destribution of the data for \",\"val\",\": \\n\",val_clean_df.groupby(\"label\").size(),'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
