{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_present.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChengYiLin/acer_intern/blob/master/Final_present.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LZGj8afVdr0",
        "colab_type": "text"
      },
      "source": [
        "# Net (using keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydIneyd8VmMd",
        "colab_type": "text"
      },
      "source": [
        "## Using drive data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly043x9RV2hc",
        "colab_type": "code",
        "outputId": "f8cbc740-8b5b-4575-93d6-1f34979f7f4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-jViOTea09v",
        "colab_type": "text"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-q0VXKdW65u",
        "colab_type": "code",
        "outputId": "e82f64c2-d19b-4caf-ee6d-1bb0c20a6470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "# keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Concatenate, Input\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "# application\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.inception_v3 import InceptionV3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D6Bf3hucdFz",
        "colab_type": "text"
      },
      "source": [
        "## Using gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIbS9W-haoe0",
        "colab_type": "code",
        "outputId": "3e217e7f-1836-4185-e495-be84e4d0937c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Dec 17 12:12:13 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMz4HCPXa454",
        "colab_type": "text"
      },
      "source": [
        "## load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mxek2-vxl_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/content/drive/My Drive/acer_intern/Final Presentation//data/New'\n",
        "saved_path ='/content/drive/My Drive/acer_intern/Final Presentation/saved_model/New'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DibqzIQoXYCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.load(os.path.sep.join([root_path, 'train_data.npy']))\n",
        "train_label = np.load(os.path.sep.join([root_path, 'train_label.npy']))\n",
        "test_data = np.load(os.path.sep.join([root_path, 'test_data.npy']))\n",
        "test_label = np.load(os.path.sep.join([root_path, 'test_label.npy']))\n",
        "val_data = np.load(os.path.sep.join([root_path, 'val_data.npy']))\n",
        "val_label = np.load(os.path.sep.join([root_path, 'val_label.npy']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZrx9ZodkW-U",
        "colab_type": "code",
        "outputId": "82a01fa7-5fbd-46b0-8056-1cf97feea35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(\"train_data : \\t\", train_data.shape)\n",
        "print(\"train_label : \\t\", train_label.shape)\n",
        "print(\"test_data : \\t\", test_data.shape)\n",
        "print(\"test_label : \\t\", test_label.shape)\n",
        "print(\"val_data : \\t\", val_data.shape)\n",
        "print(\"val_label : \\t\", val_label.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data : \t (2682, 1000, 1000, 1)\n",
            "train_label : \t (2682,)\n",
            "test_data : \t (100, 1000, 1000, 1)\n",
            "test_label : \t (100,)\n",
            "val_data : \t (100, 1000, 1000, 1)\n",
            "val_label : \t (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEJnKxzif2ih",
        "colab_type": "text"
      },
      "source": [
        "## 整理 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QFLVHgPd5ky",
        "colab_type": "code",
        "outputId": "dc96a473-640f-4f01-a774-623fd159ddd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# To categorical\n",
        "train_label = to_categorical(train_label)\n",
        "test_label = to_categorical(test_label)\n",
        "val_label = to_categorical(val_label)\n",
        "\n",
        "data_shape = ((train_data, train_label,'train'), (test_data, test_label,'test'), (val_data, val_label,'validation'))\n",
        "for data,label,using in data_shape:\n",
        "    print(\"The shape of {} data : {}\".format(using, data.shape))\n",
        "    print(\"The shape of {} label : {}\\n\".format(using, label.shape))\n",
        "    \n",
        "# # validation data 太多，我們隨機取400個來用\n",
        "# train_data = train_data[:-1]   \n",
        "# train_label = train_label[:-1]\n",
        "# np.random.seed(3)\n",
        "# np.random.shuffle(val_data)\n",
        "# np.random.seed(3)\n",
        "# np.random.shuffle(val_label)\n",
        "# val_data = val_data[:100]\n",
        "# val_label = val_label[:100]\n",
        "\n",
        "# print(\"============\\n   Renew   \\n============\")\n",
        "# data_shape = ((train_data, train_label,'train'), (test_data, test_label,'test'), (val_data, val_label,'validation'))\n",
        "# for data,label,using in data_shape:\n",
        "#     print(\"The shape of {} data : {}\".format(using, data.shape))\n",
        "#     print(\"The shape of {} label : {}\\n\".format(using, label.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of train data : (2682, 1000, 1000, 1)\n",
            "The shape of train label : (2682, 2)\n",
            "\n",
            "The shape of test data : (100, 1000, 1000, 1)\n",
            "The shape of test label : (100, 2)\n",
            "\n",
            "The shape of validation data : (100, 1000, 1000, 1)\n",
            "The shape of validation label : (100, 2)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJztA9Rxf7r7",
        "colab_type": "text"
      },
      "source": [
        "## MobileNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmFjzREj0l4K",
        "colab_type": "code",
        "outputId": "1e2c7b08-955f-4101-b347-8a28770eaf7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "img_input = Input(shape=(1000,1000,1))\n",
        "img_conc = Concatenate()([img_input, img_input, img_input])    \n",
        "\n",
        "mobileNet = MobileNet(include_top=True, \n",
        "                         weights=None,\n",
        "                         input_tensor=img_conc,\n",
        "                         input_shape=(1000, 1000, 3),\n",
        "                         pooling=None,\n",
        "                         classes=2)\n",
        "\n",
        "mobileNet.summary()\n",
        "\n",
        "# Definite the callback function\n",
        "callbacks_list = [EarlyStopping(monitor='val_loss',\n",
        "                                patience=3),\n",
        "                  ModelCheckpoint(filepath=os.path.sep.join([saved_path, 'mobileNet.h5']),\n",
        "                                  monitor='val_loss',\n",
        "                                  save_best_only=True)]\n",
        "\n",
        "# Compile\n",
        "mobileNet.compile(loss='binary_crossentropy',\n",
        "                       optimizer=Adam(),\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# inismtialize the number of epochs and batch size\n",
        "EPOCHS = 100\n",
        "BS = 10\n",
        "\n",
        "# train the model\n",
        "mobileNet.fit(x=train_data, \n",
        "              y=train_label, \n",
        "              batch_size=BS, \n",
        "              epochs=EPOCHS, \n",
        "              validation_data=(val_data, val_label), \n",
        "              callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"mobilenet_1.00_1000\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1000, 1000, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1000, 1000, 3 0           input_1[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 1001, 1001, 3 0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 500, 500, 32) 864         conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 500, 500, 32) 128         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (ReLU)               (None, 500, 500, 32) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)     (None, 500, 500, 32) 288         conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormalizatio (None, 500, 500, 32) 128         conv_dw_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)           (None, 500, 500, 32) 0           conv_dw_1_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_1 (Conv2D)              (None, 500, 500, 64) 2048        conv_dw_1_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormalizatio (None, 500, 500, 64) 256         conv_pw_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)           (None, 500, 500, 64) 0           conv_pw_1_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)      (None, 501, 501, 64) 0           conv_pw_1_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)     (None, 250, 250, 64) 576         conv_pad_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormalizatio (None, 250, 250, 64) 256         conv_dw_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)           (None, 250, 250, 64) 0           conv_dw_2_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_2 (Conv2D)              (None, 250, 250, 128 8192        conv_dw_2_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormalizatio (None, 250, 250, 128 512         conv_pw_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)           (None, 250, 250, 128 0           conv_pw_2_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)     (None, 250, 250, 128 1152        conv_pw_2_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormalizatio (None, 250, 250, 128 512         conv_dw_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)           (None, 250, 250, 128 0           conv_dw_3_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_3 (Conv2D)              (None, 250, 250, 128 16384       conv_dw_3_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormalizatio (None, 250, 250, 128 512         conv_pw_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)           (None, 250, 250, 128 0           conv_pw_3_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)      (None, 251, 251, 128 0           conv_pw_3_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)     (None, 125, 125, 128 1152        conv_pad_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormalizatio (None, 125, 125, 128 512         conv_dw_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)           (None, 125, 125, 128 0           conv_dw_4_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_4 (Conv2D)              (None, 125, 125, 256 32768       conv_dw_4_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormalizatio (None, 125, 125, 256 1024        conv_pw_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)           (None, 125, 125, 256 0           conv_pw_4_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)     (None, 125, 125, 256 2304        conv_pw_4_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormalizatio (None, 125, 125, 256 1024        conv_dw_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)           (None, 125, 125, 256 0           conv_dw_5_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_5 (Conv2D)              (None, 125, 125, 256 65536       conv_dw_5_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormalizatio (None, 125, 125, 256 1024        conv_pw_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)           (None, 125, 125, 256 0           conv_pw_5_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)      (None, 126, 126, 256 0           conv_pw_5_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)     (None, 62, 62, 256)  2304        conv_pad_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormalizatio (None, 62, 62, 256)  1024        conv_dw_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)           (None, 62, 62, 256)  0           conv_dw_6_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_6 (Conv2D)              (None, 62, 62, 512)  131072      conv_dw_6_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormalizatio (None, 62, 62, 512)  2048        conv_pw_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)           (None, 62, 62, 512)  0           conv_pw_6_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)     (None, 62, 62, 512)  4608        conv_pw_6_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormalizatio (None, 62, 62, 512)  2048        conv_dw_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)           (None, 62, 62, 512)  0           conv_dw_7_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_7 (Conv2D)              (None, 62, 62, 512)  262144      conv_dw_7_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormalizatio (None, 62, 62, 512)  2048        conv_pw_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)           (None, 62, 62, 512)  0           conv_pw_7_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)     (None, 62, 62, 512)  4608        conv_pw_7_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormalizatio (None, 62, 62, 512)  2048        conv_dw_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)           (None, 62, 62, 512)  0           conv_dw_8_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_8 (Conv2D)              (None, 62, 62, 512)  262144      conv_dw_8_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormalizatio (None, 62, 62, 512)  2048        conv_pw_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)           (None, 62, 62, 512)  0           conv_pw_8_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)     (None, 62, 62, 512)  4608        conv_pw_8_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormalizatio (None, 62, 62, 512)  2048        conv_dw_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)           (None, 62, 62, 512)  0           conv_dw_9_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_9 (Conv2D)              (None, 62, 62, 512)  262144      conv_dw_9_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormalizatio (None, 62, 62, 512)  2048        conv_pw_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)           (None, 62, 62, 512)  0           conv_pw_9_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D)    (None, 62, 62, 512)  4608        conv_pw_9_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormalizati (None, 62, 62, 512)  2048        conv_dw_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)          (None, 62, 62, 512)  0           conv_dw_10_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_10 (Conv2D)             (None, 62, 62, 512)  262144      conv_dw_10_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormalizati (None, 62, 62, 512)  2048        conv_pw_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)          (None, 62, 62, 512)  0           conv_pw_10_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D)    (None, 62, 62, 512)  4608        conv_pw_10_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormalizati (None, 62, 62, 512)  2048        conv_dw_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)          (None, 62, 62, 512)  0           conv_dw_11_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_11 (Conv2D)             (None, 62, 62, 512)  262144      conv_dw_11_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormalizati (None, 62, 62, 512)  2048        conv_pw_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)          (None, 62, 62, 512)  0           conv_pw_11_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)     (None, 63, 63, 512)  0           conv_pw_11_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D)    (None, 31, 31, 512)  4608        conv_pad_12[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormalizati (None, 31, 31, 512)  2048        conv_dw_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)          (None, 31, 31, 512)  0           conv_dw_12_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_12 (Conv2D)             (None, 31, 31, 1024) 524288      conv_dw_12_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormalizati (None, 31, 31, 1024) 4096        conv_pw_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)          (None, 31, 31, 1024) 0           conv_pw_12_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D)    (None, 31, 31, 1024) 9216        conv_pw_12_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormalizati (None, 31, 31, 1024) 4096        conv_dw_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)          (None, 31, 31, 1024) 0           conv_dw_13_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_13 (Conv2D)             (None, 31, 31, 1024) 1048576     conv_dw_13_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormalizati (None, 31, 31, 1024) 4096        conv_pw_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)          (None, 31, 31, 1024) 0           conv_pw_13_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 1024)         0           conv_pw_13_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 1024)   0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1, 1, 1024)   0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_preds (Conv2D)             (None, 1, 1, 2)      2050        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 2)            0           conv_preds[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "act_softmax (Activation)        (None, 2)            0           reshape_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,230,914\n",
            "Trainable params: 3,209,026\n",
            "Non-trainable params: 21,888\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 2682 samples, validate on 100 samples\n",
            "Epoch 1/100\n",
            "2682/2682 [==============================] - 282s 105ms/step - loss: 0.2183 - acc: 0.9146 - val_loss: 7.5342 - val_acc: 0.5300\n",
            "Epoch 2/100\n",
            "2682/2682 [==============================] - 270s 101ms/step - loss: 0.1754 - acc: 0.9359 - val_loss: 0.2162 - val_acc: 0.8900\n",
            "Epoch 3/100\n",
            "2682/2682 [==============================] - 271s 101ms/step - loss: 0.1424 - acc: 0.9441 - val_loss: 0.6749 - val_acc: 0.7500\n",
            "Epoch 4/100\n",
            "2682/2682 [==============================] - 272s 101ms/step - loss: 0.1255 - acc: 0.9567 - val_loss: 0.1011 - val_acc: 0.9600\n",
            "Epoch 5/100\n",
            "2682/2682 [==============================] - 271s 101ms/step - loss: 0.1088 - acc: 0.9601 - val_loss: 0.2533 - val_acc: 0.9200\n",
            "Epoch 6/100\n",
            "2682/2682 [==============================] - 271s 101ms/step - loss: 0.0937 - acc: 0.9672 - val_loss: 0.3001 - val_acc: 0.8900\n",
            "Epoch 7/100\n",
            "2682/2682 [==============================] - 271s 101ms/step - loss: 0.1020 - acc: 0.9601 - val_loss: 0.0622 - val_acc: 0.9700\n",
            "Epoch 8/100\n",
            "2682/2682 [==============================] - 272s 101ms/step - loss: 0.1319 - acc: 0.9500 - val_loss: 0.2351 - val_acc: 0.9100\n",
            "Epoch 9/100\n",
            "2682/2682 [==============================] - 271s 101ms/step - loss: 0.0991 - acc: 0.9612 - val_loss: 0.1654 - val_acc: 0.9400\n",
            "Epoch 10/100\n",
            "2682/2682 [==============================] - 270s 101ms/step - loss: 0.0900 - acc: 0.9698 - val_loss: 0.1267 - val_acc: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b96de9128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mso01lmBcGHQ",
        "colab_type": "code",
        "outputId": "0b748bf1-a469-41ed-b96a-ee94b9b7cbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mobileNet = load_model(os.path.sep.join([saved_path,\"mobileNet.h5\"]))\n",
        "loss,acc = mobileNet.evaluate(test_data,test_label)\n",
        "print(\"Acc : {}\".format(acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 4s 44ms/step\n",
            "Acc : 98.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeVFZyfh-dFE",
        "colab_type": "text"
      },
      "source": [
        "## Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrQUJ3yZCHvi",
        "colab_type": "code",
        "outputId": "789a2cef-5a17-4b52-819a-98d9ca297035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "img_input = Input(shape=(1000,1000,1))\n",
        "img_conc = Concatenate()([img_input, img_input, img_input])      \n",
        "\n",
        "ResNet50 = ResNet50(include_top=True,\n",
        "                    weights=None,\n",
        "                    input_tensor=img_conc,\n",
        "                    input_shape=(1000, 1000, 3),\n",
        "                    pooling=None,\n",
        "                    classes=2)\n",
        "\n",
        "ResNet50.summary()\n",
        "\n",
        "# Definite the callback function\n",
        "callbacks_list = [EarlyStopping(monitor='val_loss',\n",
        "                                patience=3),\n",
        "                  ModelCheckpoint(filepath=os.path.sep.join([saved_path, 'resnet50.h5']),\n",
        "                                  monitor='val_loss',\n",
        "                                  save_best_only=True)]\n",
        "\n",
        "# Compile\n",
        "ResNet50.compile(loss='binary_crossentropy',\n",
        "                       optimizer=Adam(),\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# inismtialize the number of epochs and batch size\n",
        "EPOCHS = 100\n",
        "BS = 5\n",
        "\n",
        "# train the model\n",
        "ResNet50.fit(x=train_data, \n",
        "           y=train_label, \n",
        "           batch_size=BS, \n",
        "           epochs=EPOCHS, \n",
        "           validation_data=(val_data, val_label),  \n",
        "           callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1000, 1000, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1000, 1000, 3 0           input_1[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 1006, 1006, 3 0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 500, 500, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 500, 500, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 500, 500, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 502, 502, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 250, 250, 64) 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 250, 250, 64) 4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 250, 250, 64) 256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 250, 250, 64) 0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 250, 250, 64) 36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 250, 250, 64) 256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 250, 250, 64) 0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 250, 250, 256 16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 250, 250, 256 16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 250, 250, 256 1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 250, 250, 256 1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 250, 250, 256 0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 250, 250, 256 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 250, 250, 64) 16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 250, 250, 64) 256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 250, 250, 64) 0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 250, 250, 64) 36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 250, 250, 64) 256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 250, 250, 64) 0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 250, 250, 256 16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 250, 250, 256 1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 250, 250, 256 0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 250, 250, 256 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 250, 250, 64) 16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 250, 250, 64) 256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 250, 250, 64) 0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 250, 250, 64) 36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 250, 250, 64) 256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 250, 250, 64) 0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 250, 250, 256 16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 250, 250, 256 1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 250, 250, 256 0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 250, 250, 256 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 125, 125, 128 32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 125, 125, 128 512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 125, 125, 128 0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 125, 125, 128 147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 125, 125, 128 512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 125, 125, 128 0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 125, 125, 512 66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 125, 125, 512 131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 125, 125, 512 2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 125, 125, 512 2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 125, 125, 512 0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 125, 125, 512 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 125, 125, 128 65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 125, 125, 128 512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 125, 125, 128 0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 125, 125, 128 147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 125, 125, 128 512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 125, 125, 128 0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 125, 125, 512 66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 125, 125, 512 2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 125, 125, 512 0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 125, 125, 512 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 125, 125, 128 65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 125, 125, 128 512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 125, 125, 128 0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 125, 125, 128 147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 125, 125, 128 512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 125, 125, 128 0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 125, 125, 512 66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 125, 125, 512 2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 125, 125, 512 0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 125, 125, 512 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 125, 125, 128 65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 125, 125, 128 512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 125, 125, 128 0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 125, 125, 128 147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 125, 125, 128 512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 125, 125, 128 0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 125, 125, 512 66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 125, 125, 512 2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 125, 125, 512 0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 125, 125, 512 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 63, 63, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 63, 63, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 63, 63, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 63, 63, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 63, 63, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 63, 63, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 63, 63, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 63, 63, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 63, 63, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 63, 63, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 63, 63, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 63, 63, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 63, 63, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 63, 63, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 63, 63, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 63, 63, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 63, 63, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 63, 63, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 63, 63, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 63, 63, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 63, 63, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 63, 63, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 63, 63, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 63, 63, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 63, 63, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 63, 63, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 63, 63, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 63, 63, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 63, 63, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 63, 63, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 63, 63, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 63, 63, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 63, 63, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 63, 63, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 63, 63, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 63, 63, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 63, 63, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 63, 63, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 63, 63, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 63, 63, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 63, 63, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 63, 63, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 63, 63, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 63, 63, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 63, 63, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 63, 63, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 63, 63, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 63, 63, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 63, 63, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 63, 63, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 63, 63, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 63, 63, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 63, 63, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 63, 63, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 63, 63, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 63, 63, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 63, 63, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 63, 63, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 63, 63, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 63, 63, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 63, 63, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 63, 63, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 32, 32, 512)  524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 32, 32, 2048) 1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 32, 32, 2048) 2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 32, 32, 2048) 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 32, 32, 2048) 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 32, 32, 2048) 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 2048) 0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 32, 32, 512)  1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 32, 32, 2048) 1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 32, 32, 2048) 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 32, 32, 2048) 0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 32, 32, 2048) 0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 32, 32, 512)  1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 32, 32, 512)  0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 32, 32, 512)  0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 32, 32, 2048) 1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 32, 32, 2048) 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 32, 32, 2048) 0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 32, 32, 2048) 0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "fc1000 (Dense)                  (None, 2)            4098        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,591,810\n",
            "Trainable params: 23,538,690\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 2682 samples, validate on 100 samples\n",
            "Epoch 1/100\n",
            "2682/2682 [==============================] - 361s 134ms/step - loss: 0.3298 - acc: 0.8855 - val_loss: 1.0143 - val_acc: 0.7700\n",
            "Epoch 2/100\n",
            "2682/2682 [==============================] - 340s 127ms/step - loss: 0.2084 - acc: 0.9262 - val_loss: 2.2873 - val_acc: 0.6900\n",
            "Epoch 3/100\n",
            "2682/2682 [==============================] - 340s 127ms/step - loss: 0.1292 - acc: 0.9545 - val_loss: 0.1729 - val_acc: 0.9600\n",
            "Epoch 4/100\n",
            "2682/2682 [==============================] - 340s 127ms/step - loss: 0.1319 - acc: 0.9515 - val_loss: 0.0962 - val_acc: 0.9700\n",
            "Epoch 5/100\n",
            "2682/2682 [==============================] - 340s 127ms/step - loss: 0.1252 - acc: 0.9538 - val_loss: 0.4187 - val_acc: 0.8500\n",
            "Epoch 6/100\n",
            "2682/2682 [==============================] - 340s 127ms/step - loss: 0.0977 - acc: 0.9661 - val_loss: 2.0314 - val_acc: 0.4600\n",
            "Epoch 7/100\n",
            "2682/2682 [==============================] - 340s 127ms/step - loss: 0.1014 - acc: 0.9676 - val_loss: 0.1715 - val_acc: 0.9200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9699b0bb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8P-ug4Q9cFJ",
        "colab_type": "code",
        "outputId": "dbd13dfb-c6f9-458a-b216-1070e897a0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "resnet = load_model(os.path.sep.join([saved_path,\"resnet50.h5\"]))\n",
        "loss,acc = resnet.evaluate(test_data,test_label)\n",
        "print(\"Acc : {}\".format(acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 9s 89ms/step\n",
            "Acc : 98.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thzm5PSFloBm",
        "colab_type": "text"
      },
      "source": [
        "## Inception V3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-8d6Q808vxR",
        "colab_type": "code",
        "outputId": "cf7b8c9a-e968-4e15-d4ae-15c519279bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.layers import Input, Concatenate\n",
        "\n",
        "img_input = Input(shape=(1000,1000,1))\n",
        "img_conc = Concatenate()([img_input, img_input, img_input])    \n",
        "\n",
        "Inception_V3 = InceptionV3(include_top=True, \n",
        "                           weights=None, \n",
        "                           input_tensor=img_conc, \n",
        "                           input_shape=(1000,1000, 3), \n",
        "                           pooling=None, \n",
        "                           classes=2)\n",
        "\n",
        "Inception_V3.summary()\n",
        "\n",
        "# Definite the callback function\n",
        "callbacks_list = [EarlyStopping(monitor='val_loss',\n",
        "                                patience=3),\n",
        "                  ModelCheckpoint(filepath=os.path.sep.join([saved_path, 'InceptionV3.h5']),\n",
        "                                  monitor='val_loss',\n",
        "                                  save_best_only=True)]\n",
        "\n",
        "# Compile\n",
        "Inception_V3.compile(loss='binary_crossentropy',\n",
        "                           optimizer=Adam(),\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# inismtialize the number of epochs and batch size\n",
        "EPOCHS = 100\n",
        "BS = 10\n",
        "\n",
        "# train the model\n",
        "Inception_V3.fit(x=train_data[300:-300], \n",
        "                       y=train_label[300:-300], \n",
        "                       batch_size=BS, \n",
        "                       epochs=EPOCHS, \n",
        "                       validation_data=(val_data, val_label),  \n",
        "                       callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1000, 1000, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1000, 1000, 3 0           input_1[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 499, 499, 32) 864         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 499, 499, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 499, 499, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 497, 497, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 497, 497, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 497, 497, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 497, 497, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 497, 497, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 497, 497, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 248, 248, 64) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 248, 248, 80) 5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 248, 248, 80) 240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 248, 248, 80) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 246, 246, 192 138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 246, 246, 192 576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 246, 246, 192 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 122, 122, 192 0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 122, 122, 64) 12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 122, 122, 64) 192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 122, 122, 64) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 122, 122, 48) 9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 122, 122, 96) 55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 122, 122, 48) 144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 122, 122, 96) 288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 122, 122, 48) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 122, 122, 96) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 122, 122, 192 0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 122, 122, 64) 12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 122, 122, 64) 76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 122, 122, 96) 82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 122, 122, 32) 6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 122, 122, 64) 192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 122, 122, 64) 192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 122, 122, 96) 288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 122, 122, 32) 96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 122, 122, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 122, 122, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 122, 122, 96) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 122, 122, 32) 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 122, 122, 256 0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 122, 122, 64) 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 122, 122, 64) 192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 122, 122, 64) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 122, 122, 48) 12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 122, 122, 96) 55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 122, 122, 48) 144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 122, 122, 96) 288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 122, 122, 48) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 122, 122, 96) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 122, 122, 256 0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 122, 122, 64) 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 122, 122, 64) 76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 122, 122, 96) 82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 122, 122, 64) 16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 122, 122, 64) 192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 122, 122, 64) 192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 122, 122, 96) 288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 122, 122, 64) 192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 122, 122, 64) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 122, 122, 64) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 122, 122, 96) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 122, 122, 64) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 122, 122, 288 0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 122, 122, 64) 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 122, 122, 64) 192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 122, 122, 64) 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 122, 122, 48) 13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 122, 122, 96) 55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 122, 122, 48) 144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 122, 122, 96) 288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 122, 122, 48) 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 122, 122, 96) 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 122, 122, 288 0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 122, 122, 64) 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 122, 122, 64) 76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 122, 122, 96) 82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 122, 122, 64) 18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 122, 122, 64) 192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 122, 122, 64) 192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 122, 122, 96) 288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 122, 122, 64) 192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 122, 122, 64) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 122, 122, 64) 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 122, 122, 96) 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 122, 122, 64) 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 122, 122, 288 0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 122, 122, 64) 18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 122, 122, 64) 192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 122, 122, 64) 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 122, 122, 96) 55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 122, 122, 96) 288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 122, 122, 96) 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 60, 60, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 60, 60, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 60, 60, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 60, 60, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 60, 60, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 60, 60, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 60, 60, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 60, 60, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 60, 60, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 60, 60, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 60, 60, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 60, 60, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 60, 60, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 60, 60, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 60, 60, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 60, 60, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 60, 60, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 60, 60, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 60, 60, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 60, 60, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 60, 60, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 60, 60, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 60, 60, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 60, 60, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 60, 60, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 60, 60, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 60, 60, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 60, 60, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 60, 60, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 60, 60, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 60, 60, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 60, 60, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 60, 60, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 60, 60, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 60, 60, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 60, 60, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 60, 60, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 60, 60, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 60, 60, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 60, 60, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 60, 60, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 60, 60, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 60, 60, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 60, 60, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 60, 60, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 60, 60, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 60, 60, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 60, 60, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 60, 60, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 60, 60, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 60, 60, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 60, 60, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 60, 60, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 60, 60, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 60, 60, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 60, 60, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 60, 60, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 60, 60, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 60, 60, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 60, 60, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 60, 60, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 60, 60, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 60, 60, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 60, 60, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 60, 60, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 60, 60, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 60, 60, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 60, 60, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 60, 60, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 60, 60, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 60, 60, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 60, 60, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 60, 60, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 60, 60, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 60, 60, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 60, 60, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 60, 60, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 60, 60, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 60, 60, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 60, 60, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 60, 60, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 60, 60, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 60, 60, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 60, 60, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 60, 60, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 60, 60, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 60, 60, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 60, 60, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 60, 60, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 60, 60, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 60, 60, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 60, 60, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 60, 60, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 60, 60, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 60, 60, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 60, 60, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 60, 60, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 60, 60, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 60, 60, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 60, 60, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 60, 60, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 60, 60, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 60, 60, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 60, 60, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 60, 60, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 60, 60, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 60, 60, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 60, 60, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 60, 60, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 60, 60, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 60, 60, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 60, 60, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 60, 60, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 60, 60, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 60, 60, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 60, 60, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 60, 60, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 60, 60, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 60, 60, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 60, 60, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 60, 60, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 60, 60, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 60, 60, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 60, 60, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 60, 60, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 60, 60, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 60, 60, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 60, 60, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 60, 60, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 60, 60, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 60, 60, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 60, 60, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 60, 60, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 60, 60, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 60, 60, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 60, 60, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 60, 60, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 60, 60, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 60, 60, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 60, 60, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 60, 60, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 60, 60, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 60, 60, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 60, 60, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 60, 60, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 60, 60, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 60, 60, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 60, 60, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 29, 29, 320)  552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 29, 29, 192)  331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 29, 29, 320)  960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 29, 29, 192)  576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 29, 29, 320)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 29, 29, 192)  0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 29, 29, 768)  0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 29, 29, 1280) 0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 29, 29, 448)  573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 29, 29, 448)  1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 29, 29, 448)  0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 29, 29, 384)  491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 29, 29, 384)  1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 29, 29, 384)  1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 29, 29, 384)  1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 29, 29, 384)  0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 29, 29, 384)  0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 29, 29, 384)  442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 29, 29, 384)  442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 29, 29, 384)  442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 29, 29, 384)  442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 29, 29, 1280) 0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 29, 29, 320)  409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 29, 29, 384)  1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 29, 29, 384)  1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 29, 29, 384)  1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 29, 29, 384)  1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 29, 29, 192)  245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 29, 29, 320)  960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 29, 29, 384)  0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 29, 29, 384)  0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 29, 29, 384)  0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 29, 29, 384)  0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 29, 29, 192)  576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 29, 29, 320)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 29, 29, 768)  0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 29, 29, 768)  0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 29, 29, 192)  0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 29, 29, 2048) 0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 29, 29, 448)  917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 29, 29, 448)  1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 29, 29, 448)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 29, 29, 384)  786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 29, 29, 384)  1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 29, 29, 384)  1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 29, 29, 384)  1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 29, 29, 384)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 29, 29, 384)  0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 29, 29, 384)  442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 29, 29, 384)  442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 29, 29, 384)  442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 29, 29, 384)  442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 29, 29, 2048) 0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 29, 29, 320)  655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 29, 29, 384)  1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 29, 29, 384)  1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 29, 29, 384)  1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 29, 29, 384)  1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 29, 29, 192)  393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 29, 29, 320)  960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 29, 29, 384)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 29, 29, 384)  0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 29, 29, 384)  0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 29, 29, 384)  0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 29, 29, 192)  576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 29, 29, 320)  0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 29, 29, 768)  0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 29, 29, 768)  0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 29, 29, 192)  0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 29, 29, 2048) 0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 2)            4098        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 21,806,882\n",
            "Trainable params: 21,772,450\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 2082 samples, validate on 100 samples\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7d83def51655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                        \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                        callbacks=callbacks_list)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[10,60,60,192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_64-0-0-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/mul/_2883]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[10,60,60,192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_64-0-0-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mr8KhU_m1jh",
        "colab_type": "code",
        "outputId": "c5705aa7-26ac-4e71-ccfa-86630b3f6b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "Inception_V3 = load_model(os.path.sep.join([saved_path, 'InceptionV3.h5']))\n",
        "loss,acc = Inception_V3.evaluate(test_data,test_label)\n",
        "print(\"Acc : {}\".format(acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 12s 121ms/step\n",
            "Acc : 99.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3TbYJw0DzDF",
        "colab_type": "text"
      },
      "source": [
        "# Final plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck5H1C0hRKGC",
        "colab_type": "text"
      },
      "source": [
        "## Compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wirTh8ilRGDL",
        "colab_type": "code",
        "outputId": "bc222264-07c9-4925-f58f-9f861a258212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "mobilenet = load_model(os.path.sep.join([saved_path, 'mobileNet.h5']))\n",
        "loss,acc = mobilenet.evaluate(test_data,test_label)\n",
        "print(\"mobilenet Acc : {}\".format(acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "100/100 [==============================] - 7s 74ms/step\n",
            "mobilenet Acc : 98.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrVu-3RJSK3k",
        "colab_type": "code",
        "outputId": "cced2f86-31ed-48ef-af0e-3587eca02944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "resnet50 = load_model(os.path.sep.join([saved_path, 'resnet50.h5']))\n",
        "loss,acc = resnet50.evaluate(test_data,test_label)\n",
        "print(\"resnet50 Acc : {}\".format(acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "100/100 [==============================] - 8s 80ms/step\n",
            "resnet50 Acc : 98.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq6VUSoyQe9R",
        "colab_type": "code",
        "outputId": "1561ed9b-04c7-4cf5-d975-6e5e7d80caa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "Inception_V3 = load_model(os.path.sep.join([saved_path, 'InceptionV3.h5']))\n",
        "loss,acc = Inception_V3.evaluate(test_data,test_label)\n",
        "print(\"Acc : {}\".format(acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "100/100 [==============================] - 10s 102ms/step\n",
            "Acc : 99.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alvy98ccTU1B",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjkTI35QTSW2",
        "colab_type": "code",
        "outputId": "f52d6e75-f029-47b4-f604-90aa51662f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mobilenet = mobilenet.predict(test_data)\n",
        "mobilenet_predict = [ np.argmax(i) for i in mobilenet]\n",
        "mobilenet_predict = np.asarray(mobilenet_predict)\n",
        "mobilenet_predict.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0BOTDZ-TS7V",
        "colab_type": "code",
        "outputId": "2f9db5a1-2282-434f-ea95-1b5b54a65c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "resnet_50 = resnet50.predict(test_data)\n",
        "resnet_50_predict = [ np.argmax(i) for i in resnet_50]\n",
        "resnet_50_predict = np.asarray(resnet_50_predict)\n",
        "resnet_50_predict.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYW-E9zfTTdb",
        "colab_type": "code",
        "outputId": "a04cbb3e-bb67-4320-b25c-230104911eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "IV3 = Inception_V3.predict(test_data)\n",
        "IV3_predict = [ np.argmax(i) for i in IV3]\n",
        "IV3_predict = np.asarray(IV3_predict)\n",
        "IV3_predict.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXCN536TJ4M",
        "colab_type": "text"
      },
      "source": [
        "## Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmmfAeWbSF1q",
        "colab_type": "code",
        "outputId": "054ede96-614a-499e-cb0e-dd3be52a247b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "y = np.load(os.path.sep.join([root_path, 'test_label.npy']))\n",
        "\n",
        "mobilenet_scores = mobilenet_predict\n",
        "mobilenet_fpr, mobilenet_tpr, _ = roc_curve(y, mobilenet_scores)\n",
        "mobilenet_roc_auc = auc(mobilenet_fpr, mobilenet_tpr)\n",
        "\n",
        "resnet_50_scores = resnet_50_predict\n",
        "resnet_50_fpr, resnet_50_tpr, _ = roc_curve(y, resnet_50_scores)\n",
        "resnet_50_roc_auc = auc(resnet_50_fpr, resnet_50_tpr)\n",
        "\n",
        "IV3_scores = IV3_predict\n",
        "IV3_fpr, IV3_tpr, _ = roc_curve(y, IV3_scores)\n",
        "IV3_roc_auc = auc(IV3_fpr, IV3_tpr)\n",
        "\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "lw = 2\n",
        "plt.plot(mobilenet_fpr, mobilenet_tpr, color='blue', lw=lw, label='MobileNet   (auc = %0.2f)' % mobilenet_roc_auc)\n",
        "plt.plot(resnet_50_fpr, resnet_50_tpr, color='red', lw=lw, label='ResNet50   (auc = %0.2f)' % resnet_50_roc_auc)\n",
        "plt.plot(IV3_fpr, IV3_tpr, color='green', lw=lw, label='GoogLeNet (auc = %0.2f)' % IV3_roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "plt.title('ROC Curve', fontsize=24)\n",
        "plt.legend(loc=\"lower right\")\n",
        "fig.savefig( os.path.sep.join([saved_path, 'Result.png']) )\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAICCAYAAAC9RaXMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKIiJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}